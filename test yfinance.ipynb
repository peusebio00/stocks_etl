{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a10f4f0b-0dcd-47e7-aff2-e68a97cb003a",
   "metadata": {},
   "source": [
    "# Automating Stock Market Data Extraction & Load\n",
    "### Extraction from yfinance module, load to Excel workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35f12769-9f85-4ad9-aec5-3d95ba2651d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the relevant modules and libraries\n",
    "\n",
    "import yfinance as yf # Module containing stock market data --> where we'll extract our figures from \n",
    "import pandas as pd   # General purpose data library\n",
    "import openpyxl       # Work with Excel documents\n",
    "import datetime       # Working with + formatting datetime objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9e17ca75-e663-4587-af44-0bc3608f5e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining yesterday's date and storing it in a formatted string, under the YYYY-MM-DD format\n",
    "# The formatted string containing yesterday's date is then stored in the 'yesterday' variable\n",
    "\n",
    "today = pd.to_datetime(datetime.date.today())\n",
    "yesterday = (today - datetime.timedelta(days=1)).strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e015587-3e84-48cf-a6e2-2545d62cae59",
   "metadata": {},
   "source": [
    ">In order to extract data from the intended stock tickers, we first need to __define what tickers we want to fetch data for__;\n",
    ">* This information will then be stored in the `stocks_list` list-object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1b837b49-0446-40da-ab26-92d0ee2fc53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_list = ['AAPL', 'MSFT']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b657c9-afb7-4037-8ec8-ca31e053299d",
   "metadata": {},
   "source": [
    "## Extraction  - `yfinance` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2ade3495-8bd6-4e11-80bc-fc51cabc7b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  2 of 2 completed\n"
     ]
    }
   ],
   "source": [
    "df = yf.download(tickers=stocks_list,\n",
    "                   period='5d',\n",
    "                   multi_level_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e379df49-40c4-4a1a-8cf3-421c4fc78cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Close</th>\n",
       "      <th colspan=\"2\" halign=\"left\">High</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Low</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Open</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-04-17</th>\n",
       "      <td>196.979996</td>\n",
       "      <td>367.779999</td>\n",
       "      <td>198.830002</td>\n",
       "      <td>374.320007</td>\n",
       "      <td>194.419998</td>\n",
       "      <td>366.890015</td>\n",
       "      <td>197.199997</td>\n",
       "      <td>373.750000</td>\n",
       "      <td>51334300</td>\n",
       "      <td>20943700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-21</th>\n",
       "      <td>193.160004</td>\n",
       "      <td>359.119995</td>\n",
       "      <td>193.800003</td>\n",
       "      <td>364.480011</td>\n",
       "      <td>189.809998</td>\n",
       "      <td>355.670013</td>\n",
       "      <td>193.270004</td>\n",
       "      <td>362.820007</td>\n",
       "      <td>46742500</td>\n",
       "      <td>20807300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-22</th>\n",
       "      <td>199.740005</td>\n",
       "      <td>366.820007</td>\n",
       "      <td>201.589996</td>\n",
       "      <td>367.769989</td>\n",
       "      <td>195.970001</td>\n",
       "      <td>359.859985</td>\n",
       "      <td>196.119995</td>\n",
       "      <td>363.380005</td>\n",
       "      <td>52976400</td>\n",
       "      <td>19485000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-23</th>\n",
       "      <td>204.600006</td>\n",
       "      <td>374.390015</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>380.390015</td>\n",
       "      <td>202.800003</td>\n",
       "      <td>373.019989</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>376.059998</td>\n",
       "      <td>52863100</td>\n",
       "      <td>20530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-24</th>\n",
       "      <td>207.869995</td>\n",
       "      <td>387.119995</td>\n",
       "      <td>208.100006</td>\n",
       "      <td>387.350006</td>\n",
       "      <td>202.940002</td>\n",
       "      <td>375.190002</td>\n",
       "      <td>204.884995</td>\n",
       "      <td>375.989990</td>\n",
       "      <td>23872309</td>\n",
       "      <td>10493581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Price            Close                    High                     Low  \\\n",
       "Ticker            AAPL        MSFT        AAPL        MSFT        AAPL   \n",
       "Date                                                                     \n",
       "2025-04-17  196.979996  367.779999  198.830002  374.320007  194.419998   \n",
       "2025-04-21  193.160004  359.119995  193.800003  364.480011  189.809998   \n",
       "2025-04-22  199.740005  366.820007  201.589996  367.769989  195.970001   \n",
       "2025-04-23  204.600006  374.390015  208.000000  380.390015  202.800003   \n",
       "2025-04-24  207.869995  387.119995  208.100006  387.350006  202.940002   \n",
       "\n",
       "Price                         Open                Volume            \n",
       "Ticker            MSFT        AAPL        MSFT      AAPL      MSFT  \n",
       "Date                                                                \n",
       "2025-04-17  366.890015  197.199997  373.750000  51334300  20943700  \n",
       "2025-04-21  355.670013  193.270004  362.820007  46742500  20807300  \n",
       "2025-04-22  359.859985  196.119995  363.380005  52976400  19485000  \n",
       "2025-04-23  373.019989  206.000000  376.059998  52863100  20530000  \n",
       "2025-04-24  375.190002  204.884995  375.989990  23872309  10493581  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fe4017-c8dc-4560-87b2-3ec2000c6a55",
   "metadata": {},
   "source": [
    "### Quick Thought on Dates:\n",
    ">Leave the `period` parameter set to '5d' within yf.download()\n",
    ">Within the `transform_df()` function, BEFORE the .stack() and .unstack() methods coming, check if df.index[-1] (`datetime` object - most recent date in the extraction) is equal to the `today` variable:\n",
    ">* If it IS equal, then keep the day before THAT only (df.index[-2])\n",
    ">* If it ISN'T equal, then keep df.index[-1] only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "833aab41-a643-4ebb-9ef8-51528f0da000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As explained above --> if today matches the last date in the extracted data, then only keep the day before that\n",
    "## This is to make sure we don't download the current day's data and thus fetch still-live stock exchange figures -- We want to fetch only the previous day's (whatever date that was) finalised values\n",
    "\n",
    "# As such, if today does NOT match the last date in the extracted data (going into the else clause), then extract the last day available in the extraction!\n",
    "## Instances where today does NOT match the last date in the extraction would occur when the extraction is done before the market opens --> the most recent date would then naturally NOT be today,\n",
    "## but rather a previous, already finalised date \n",
    "\n",
    "if today == df.index[-1]:\n",
    "    day_to_fetch = -2\n",
    "else:\n",
    "    day_to_fetch = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7b2af7cd-9a84-49b1-ad72-99fcc84fef87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Close</th>\n",
       "      <th colspan=\"2\" halign=\"left\">High</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Low</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Open</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-04-23</th>\n",
       "      <td>204.600006</td>\n",
       "      <td>374.390015</td>\n",
       "      <td>208.0</td>\n",
       "      <td>380.390015</td>\n",
       "      <td>202.800003</td>\n",
       "      <td>373.019989</td>\n",
       "      <td>206.0</td>\n",
       "      <td>376.059998</td>\n",
       "      <td>52863100</td>\n",
       "      <td>20530000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Price            Close               High                     Low              \\\n",
       "Ticker            AAPL        MSFT   AAPL        MSFT        AAPL        MSFT   \n",
       "Date                                                                            \n",
       "2025-04-23  204.600006  374.390015  208.0  380.390015  202.800003  373.019989   \n",
       "\n",
       "Price        Open                Volume            \n",
       "Ticker       AAPL        MSFT      AAPL      MSFT  \n",
       "Date                                               \n",
       "2025-04-23  206.0  376.059998  52863100  20530000  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Keeping only the intended date LIKE SO!\n",
    "\n",
    "df = df.loc[[df.index[day_to_fetch]]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4ea71a96-1912-4000-b6a3-a33e9ade60ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime('2025-04-24') == df.index[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "216f5eb1-351a-47b7-a850-fb46fe6fac26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2025-04-24 00:00:00')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a7b0d3-8251-4fcf-9855-b5c2f302523a",
   "metadata": {},
   "source": [
    "## Transformation - Cleaning the Extracted Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d708c3c-7308-413f-8102-97889956786b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_df(param_df):\n",
    "    '''\n",
    "    This function will take a df in as an input (param_df), and apply all necessary changes to it;\n",
    "    \n",
    "    Steps to be taken are:\n",
    "    - Create a copy of the dataframe for added safety\n",
    "    - Using a combination of .unstack(), .stack(), and .reset_index() to convert the originally-MultiIndex df into a simpler, neater format\n",
    "    - Drop the 'Volume' column as it is not necessary for our end goal\n",
    "    - Rename both axes (0 and 1 - rows and columns) to None, to make the dataframe look neater with no unnecessary axis names\n",
    "    - Round all columns to 2 decimal places\n",
    "    - Reorder the columns so they match the destination Excel file\n",
    "    \n",
    "    Finally, this function will end by returning the altered dataframe\n",
    "    '''\n",
    "    df_copy = param_df.copy()                                         # Creating a copy of the original df\n",
    "    df_copy = df_copy.unstack().to_frame().unstack(level=0)\\\n",
    "    .stack(level=0, future_stack=True).reset_index('Date')\\\n",
    "    .reset_index(level=1, drop=True)                                  # Using .unstack() and .stack() to get the originally-MultiIndex df to the right format\n",
    "                                                                      # Also using future_stack=True in .stack() to prevent a FutureWarning --> avoiding deprecation in future pandas versions!\n",
    "    \n",
    "    df_copy.drop(columns='Volume', inplace=True)                      # Dropping the Volume column (unnecessary)\n",
    "    \n",
    "    df_copy.rename_axis(index=None, columns=None, inplace=True)       # Renaming both the index and olumn axes to None --> dropping unnecessary axis names\n",
    "\n",
    "    for i in df_copy.drop(columns='Date').columns:\n",
    "        df_copy[i] = df_copy[i].apply(lambda x: round(x, 2))          # Looping through the columns in our df (except 'Date') and using a lambda function to round all figures to 2 decimals\n",
    "                                                                      # Note: the 'Date' column isn't actually dropped from the df as we're not using inplace=True --> it is only a 'temporary'\n",
    "                                                                      # drop so we don't attempt to round the 'Date' column --> can't round a datetime object\n",
    "\n",
    "    df_copy = df_copy[['Date', 'Open', 'High', 'Low', 'Close']]       # Reordering the columns so they match the order in the destination Excel file\n",
    "\n",
    "    return df_copy                                                    # Finally, returning the altered df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6956bd65-c333-404d-8f51-c6a4be98e4bd",
   "metadata": {},
   "source": [
    "# Note: Need to Rewrite the Markdown Below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d4d454-7044-4ced-861c-63d2623e486b",
   "metadata": {},
   "source": [
    ">Having defined the full transform_df function above with all necessary changes, we __now apply it to our original dataframe__ and __permanently change it__\n",
    ">\n",
    ">However, so as to __avoid unnecessarily running the function twice and overwriting the intended changes__, we will first make sure the __altered version of the dataframe does not yet exist__\n",
    ">\n",
    ">* If it __needs creating__, the newly-altered df will be saved in `new_df`;\n",
    ">* Hence, we will first check if `new_df in locals():`\n",
    ">    * `locals()` is a dictionary-type object which contains all the existing variables in the file\n",
    ">* If the newly-altered dataframe __has already been created__, checking `new_df in locals()` will return __`True`:__\n",
    ">    * Should be the case, we will print a warning message stating that the df exists already and thus the function will not be ran again --> thus avoiding overwriting an already-changed df\n",
    ">* If `new_df in locals()` returns False - and hence the dataframe has not yet been created - we move to the `else statement` in the if-else block and thus effectively __create new_df__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2dcedbbc-09f3-4f98-8df5-f90c86db4e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'new_df' in locals():\n",
    "    del new_df\n",
    "else:\n",
    "    pass\n",
    "\n",
    "new_df = transform_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d96397-53e9-478e-b64e-0b5bde0f1dde",
   "metadata": {},
   "source": [
    ">We now __check new_df__ to make sure it __looks exactly as intended:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9941c9c9-e558-4a62-b6fd-7b0c0eccbaa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>2025-04-22</td>\n",
       "      <td>196.07</td>\n",
       "      <td>201.55</td>\n",
       "      <td>196.00</td>\n",
       "      <td>199.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT</th>\n",
       "      <td>2025-04-22</td>\n",
       "      <td>363.38</td>\n",
       "      <td>367.76</td>\n",
       "      <td>359.86</td>\n",
       "      <td>366.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date    Open    High     Low   Close\n",
       "AAPL 2025-04-22  196.07  201.55  196.00  199.74\n",
       "MSFT 2025-04-22  363.38  367.76  359.86  366.82"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538d42d6-2436-425c-a036-7c660a95566d",
   "metadata": {},
   "source": [
    ">**Success!**\n",
    ">* The altered DataFrame is now in a __much simpler and neater format to work with__, where the __stock tickers__ are the <u>index labels</u> and the <u>only level of columns</u> are the __Date__ of the extracted figures and the __4 figures__ themselves (Open, High, Low, Close)\n",
    ">* These 4 figures are __what we want to load into the destination Excel workbook__\n",
    ">* The Date will be used __simply to match the correct row on the destination file__ -- The data will be <u>appended where the Date in new_df matches the Date column in the destination file</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4189813-92fa-4a0c-ab1d-da5b8af6b3f5",
   "metadata": {},
   "source": [
    "## Load to Excel - WIP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5b04bf-d0e1-4f38-b4fd-531b73da7293",
   "metadata": {},
   "source": [
    ">The __`Load to Excel`__ stage will be comprised of two main stages:\n",
    ">\n",
    ">**1. Reading the existing destination file:**\n",
    ">    * When appending the data to the destination file, we will need to append it to the correct row;\n",
    ">    * The correct row will be the one where the Date matches that of the previous stock data extraction;\n",
    ">        * As in, the destination file contains a Date column (which is aliased as the ticker name, lower-cased) --> this Date column is already populated with future dates. We will want to append the data onto the file only on the specific row where the Date matches the one in our previously done extraction;\n",
    ">    * As such, the reading of the destination file as crucial to __work out the correct row number to append the data to later on__\n",
    ">\n",
    ">**2. Loading the data to the existing destination file:**\n",
    ">* Once we've worked out what the correct row number to append our data to is, we will then move forward with the load of the data into the destination file, onto the correct row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54782b96-43a6-4d20-8902-2f857258a85d",
   "metadata": {},
   "source": [
    "### Reading the Destination File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75c84a0-871b-44d3-998d-9c2b3646e6c3",
   "metadata": {},
   "source": [
    ">**Key Note 1:**\n",
    ">* The destination file contains __separate sheets for each stock__\n",
    ">* The __sheet names__ are the <u>stock tickers, lower-cased</u> (e.g. the sheet with data for the AAPL ticker is named 'aapl')\n",
    ">* We will access each sheet by __looping through the elements__ in `stocks_list` (the list of tickers we downloaded data from, defined at the start of the script) \n",
    ">\n",
    ">**Steps:**\n",
    ">\n",
    ">* Save the file path within the `path` variable; \n",
    ">* Use `.read_excel()` to access each sheet in the document;\n",
    ">    * __sheet_name__ must be passed and equaled to the the ticker name (__lowered tring__);\n",
    ">    * __parse_dates__ must be set to `True`, date_format must be set to `%Y-%m-%d`\n",
    ">* Fetch the correct row number to later append the data to;\n",
    ">    * Do so by __working out where the Date value in the destination file <u>matches</u> the Date value of our extracted data__\n",
    "> \n",
    ">**Key Note 2:**\n",
    ">* We will be using `boolean masking` to work out the row where the Dates match in the Excel file --> once the row where they match has been found, we will use the `.index` attribute, followed by the [0] subscripting operator --> thus getting back an integer, which represents the row number in question.\n",
    ">* **However:**\n",
    ">    * Due to the formatting of the destination file (__headers take up 2 rows rather than just one__) AND the fact that __Python is 0-indexed whereas Excel starts each sheet at row 1__, we will then need to __add 2 to the integer we get back from the boolean masking operation__\n",
    ">    * E.g. if we find that the Dates match on row 5, that means that, __on the destination file__, the Dates would __actually match on row 7__ (5+2)\n",
    ">\n",
    ">**Key Note 3:**\n",
    ">* The separate sheets for each stock ticker follow the __exact same structure__, they're essentially __exact copies of each other__, just with <u>different figures populating the cells</u>\n",
    ">* As such, the correct row number will be __the exact same for _ALL_ sheets__\n",
    ">* Due to this, we will __only need to read _ONE_ of the sheets__ in the destination file, as this will give us the correct row number for ___ALL___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f9310ff-91c1-449e-912d-95131845e207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the file path from the current directory\n",
    "\n",
    "final_file = 'CFDv1 (2020-2025).xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "276f591f-6bb0-4610-ab7a-1b656937114d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using .read_excel() to fetch the data for each sheet in the destination file\n",
    "\n",
    "xl = pd.read_excel(final_file,                              # Path for destination file\n",
    "                   sheet_name=stocks_list[0].lower(), # Fetching only the first ticker in stocks_list (as we only need to read 1 sheet for this stage\n",
    "                                                      # Also lowering the string as names are lowered in the destination file \n",
    "                   parse_dates=True,                  # Parsing dates so we can work with them as datetime objects\n",
    "                   date_format='%Y-%m-%d')            # Defining the format dates are stored in on the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e94871d2-8d68-4587-bc23-65ffccb1ddcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aapl</th>\n",
       "      <th>opp LTT 21</th>\n",
       "      <th>opp LTT 52</th>\n",
       "      <th>indic sl 21</th>\n",
       "      <th>indic sl52</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 31</th>\n",
       "      <th>10.1</th>\n",
       "      <th>7.3</th>\n",
       "      <th>profit 4</th>\n",
       "      <th>Unnamed: 35</th>\n",
       "      <th>Unnamed: 36</th>\n",
       "      <th>Unnamed: 37</th>\n",
       "      <th>Unnamed: 38</th>\n",
       "      <th>Unnamed: 39</th>\n",
       "      <th>Unnamed: 40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>INDICADORES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.967332</td>\n",
       "      <td>-12.345492</td>\n",
       "      <td>53.621839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>date</td>\n",
       "      <td>open</td>\n",
       "      <td>high</td>\n",
       "      <td>low</td>\n",
       "      <td>close</td>\n",
       "      <td>ATR</td>\n",
       "      <td>b52</td>\n",
       "      <td>s52</td>\n",
       "      <td>b21</td>\n",
       "      <td>s21</td>\n",
       "      <td>...</td>\n",
       "      <td>LTT trend</td>\n",
       "      <td>LTT s21 ref</td>\n",
       "      <td>LTT s21 valid</td>\n",
       "      <td>profit_b21</td>\n",
       "      <td>TT_s21</td>\n",
       "      <td>low&lt;s21</td>\n",
       "      <td>e_s21</td>\n",
       "      <td>sl_s21</td>\n",
       "      <td>sl_s21_ATR</td>\n",
       "      <td>exit_s21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-10-01 00:00:00</td>\n",
       "      <td>56.267502</td>\n",
       "      <td>57.055</td>\n",
       "      <td>56.049999</td>\n",
       "      <td>56.147499</td>\n",
       "      <td>0.071786</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  aapl opp LTT 21 opp LTT 52 indic sl 21 indic sl52  \\\n",
       "0                  NaN          0          0          10         21   \n",
       "1                 date       open       high         low      close   \n",
       "2                  NaN        NaN        NaN         NaN        NaN   \n",
       "3                  NaN        NaN        NaN         NaN        NaN   \n",
       "4                  NaN        NaN        NaN         NaN        NaN   \n",
       "5                  NaN        NaN        NaN         NaN        NaN   \n",
       "6                  NaN        NaN        NaN         NaN        NaN   \n",
       "7                  NaN        NaN        NaN         NaN        NaN   \n",
       "8                  NaN        NaN        NaN         NaN        NaN   \n",
       "9  2019-10-01 00:00:00  56.267502     57.055   56.049999  56.147499   \n",
       "\n",
       "  Unnamed: 5   Unnamed: 6 Unnamed: 7 Unnamed: 8 Unnamed: 9  ... Unnamed: 31  \\\n",
       "0        NaN  INDICADORES        NaN        NaN        NaN  ...         NaN   \n",
       "1        ATR          b52        s52        b21        s21  ...   LTT trend   \n",
       "2        NaN          NaN        NaN        NaN        NaN  ...         NaN   \n",
       "3        NaN          NaN        NaN        NaN        NaN  ...         NaN   \n",
       "4        NaN          NaN        NaN        NaN        NaN  ...         NaN   \n",
       "5        NaN          NaN        NaN        NaN        NaN  ...         NaN   \n",
       "6        NaN          NaN        NaN        NaN        NaN  ...         NaN   \n",
       "7        NaN          NaN        NaN        NaN        NaN  ...         NaN   \n",
       "8        NaN          NaN        NaN        NaN        NaN  ...         NaN   \n",
       "9   0.071786          NaN        NaN        NaN        NaN  ...         NaN   \n",
       "\n",
       "          10.1            7.3    profit 4 Unnamed: 35 Unnamed: 36 Unnamed: 37  \\\n",
       "0    65.967332     -12.345492   53.621839         NaN         NaN         NaN   \n",
       "1  LTT s21 ref  LTT s21 valid  profit_b21      TT_s21     low<s21       e_s21   \n",
       "2          NaN            NaN         NaN         NaN         NaN         NaN   \n",
       "3          NaN            NaN         NaN         NaN         NaN         NaN   \n",
       "4          NaN            NaN         NaN         NaN         NaN         NaN   \n",
       "5          NaN            NaN         NaN         NaN         NaN         NaN   \n",
       "6          NaN            NaN         NaN         NaN         NaN         NaN   \n",
       "7          NaN            NaN         NaN         NaN         NaN         NaN   \n",
       "8          NaN            NaN         NaN         NaN         NaN         NaN   \n",
       "9          NaN            NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "  Unnamed: 38 Unnamed: 39 Unnamed: 40  \n",
       "0         NaN         NaN         NaN  \n",
       "1      sl_s21  sl_s21_ATR    exit_s21  \n",
       "2         NaN         NaN         NaN  \n",
       "3         NaN         NaN         NaN  \n",
       "4         NaN         NaN         NaN  \n",
       "5         NaN         NaN         NaN  \n",
       "6         NaN         NaN         NaN  \n",
       "7         NaN         NaN         NaN  \n",
       "8         NaN         NaN         NaN  \n",
       "9         NaN         NaN         NaN  \n",
       "\n",
       "[10 rows x 41 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the first 10 rows of the destination file\n",
    "\n",
    "xl.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa09801f-a44d-43d5-975d-dec7fcdf37d4",
   "metadata": {},
   "source": [
    ">Even though the file is structured in a strange manner when read using Pandas, __we will not be transforming it or cleaning it up in any way__;\n",
    ">* This is because we want to keep the file __exactly as it is__ so we can work out what the correct row number to append our data is, __without having changed it through any cleaning or transformations__\n",
    ">\n",
    ">__This is crucial to ensure accuracy in the integer we get back representing the correct row number__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c6d6b492-fba2-4a13-968c-dce61ddc6827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1422"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using boolean masking to work out what row the Dates match in\n",
    "# Then using .index followed by [0] to fetch the integer representing the correct row number\n",
    "# Storing the number in row_number\n",
    "\n",
    "row_number = xl[xl['aapl'] == new_df.loc['AAPL']['Date']].index[0]\n",
    "row_number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f365a08-fff8-4948-ba13-a37126547f02",
   "metadata": {},
   "source": [
    ">**Reminder:**\n",
    ">* As mentioned above, we now need to __add 2 to row_number to ensure accuracy__\n",
    ">* E.g. getting back 5 from the boolean masking operation means the correct row is actually 7 (5+2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c72039-5fc0-4a42-86b7-6ec15b97d5b9",
   "metadata": {},
   "source": [
    ">Additionally, we will now store the revised row number (having added 2 to it) in `correct_row`\n",
    ">* To ensure we don't accidentally add 2 to it several times and thus damage the reliability of this operation, we will:\n",
    ">* Check if correct_row exists already\n",
    ">    * If it doesn't:\n",
    ">        * We will create it and add 2 to `row_number`, storing `row_number` + 2 in `correct_row`\n",
    ">    * If it does:\n",
    ">        * We will check if correct_row - row_number == 2:\n",
    ">            * In doing this, we are making sure that we have in fact only added 2 to the original row_number and not more than that\n",
    ">            * If that returns __True__ (`correct_row` exists already _AND_ the difference between it and `row_number` __is in fact 2__), we will __do nothing else__ (`pass`)\n",
    ">            * If that returns __False__ (`correct_row` exists already _BUT_ the difference between it and `row_number` __is NOT 2__), we will once more __execute `correct_row` = `row_number` + 2 to __ensure it is the correct number, and then pass__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "72921bf9-55c6-42fb-8190-2005fa7a9bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between correct_number and the original row_number: 1\n",
      "Correct row: 1423\n"
     ]
    }
   ],
   "source": [
    "if 'correct_row' not in locals(): # correct_row does NOT yet exist\n",
    "    correct_row = row_number + 1\n",
    "else: # correct_row DOES already exist\n",
    "    if (correct_row - row_number) == 1:\n",
    "        pass\n",
    "    else:\n",
    "        correct_row = row_number + 1\n",
    "\n",
    "print(f'Difference between correct_number and the original row_number: {correct_row - row_number}')\n",
    "print(f'Correct row: {correct_row}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d5245d-8d27-4c18-8e85-a5e769ac2246",
   "metadata": {},
   "source": [
    ">Now that we've successfully worked out what the correct row number is to append our data to, we will move on to the `loading to destination file` stage! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bdb975-5565-48eb-bd7c-1191648ccedf",
   "metadata": {},
   "source": [
    ">**Key Note:**\n",
    ">* The separate sheets for each stock ticker follow the __exact same structure__, they're essentially __exact copies of each other__, just with <u>different figures populating the cells</u>\n",
    ">* As such, the correct row number will be __the exact same for _ALL_ sheets__\n",
    ">* Due to this, we __needed to read only _ONE_ sheet__ in the previous stage, as this will give us the correct row number for ___ALL___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e935b66-5e3f-4f67-9141-884a4777c096",
   "metadata": {},
   "source": [
    "### Loading the Data to Excel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc390da3-7881-46d3-993d-60efa7db7ebd",
   "metadata": {},
   "source": [
    ">Intermediate file first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0a53cfc7-9548-4bdb-be23-3db4aeee1867",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_file = 'output_file.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4243f964-360d-4043-a0d7-6569c65fb6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(intermediate_file, mode='w') as writer:\n",
    "    \n",
    "    for ticker in stocks_list:\n",
    "        data_to_append = pd.DataFrame(new_df.drop(columns='Date').loc[ticker]).transpose()\n",
    "        data_to_append.to_excel(writer, engine='openpyxl', sheet_name=ticker, index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132ea3c7-18f8-4b79-906a-5b1a38138d9f",
   "metadata": {},
   "source": [
    ">__Success in appending to intermediate file!__\n",
    ">\n",
    ">Now moving on to copying the intended cells from the intermediate and pasting into the desired range within the destination file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4b513e03-6c15-422a-a18e-fd128aa425f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# wb = openpyxl.load_workbook(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cabd5c7e-8a6b-4100-8167-14e09bf059cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_workbook = openpyxl.load_workbook(intermediate_file)\n",
    "final_workbook = openpyxl.load_workbook(final_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3ed56ac9-6acd-4ad3-9a99-6a8a5d057825",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker in stocks_list:\n",
    "    source_sheet = intermediate_workbook[ticker]\n",
    "    target_sheet = final_workbook[ticker.lower()] # sheet names in the final destination file are the lower-cased ticker names\n",
    "\n",
    "    source_range = source_sheet['A1:D1'] # The range to copy from in the intermediate file will always be [A1:D1] for every single sheet\n",
    "    start_col_dest_file = 2 # Paste the data starting from column B in the destination file\n",
    "\n",
    "    for col_offset, source_cell in enumerate(source_range[0]):  # source_range[0] gets the first (and only) row\n",
    "                target_column = start_col_dest_file + col_offset # col_offset will loop through the 4 columns in the data (A to D), with numerical values 0 to 3\n",
    "                target_cell = target_sheet.cell(row=correct_row, column=target_column)\n",
    "                target_cell.value = source_cell.value\n",
    "    final_workbook.save(final_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c76d0a-b4f4-4d3f-9531-0cc1853cb9c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a403d43-c0cc-4f63-bbe6-17646b3df983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4de1121-73ac-4c3e-863c-eb4f87245767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d576e9-23d2-4fd2-9261-42720779e73e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389bf66a-0d46-4abe-a399-6e44156c5bb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d972a3cb-ea16-48e0-b467-2002340f1915",
   "metadata": {},
   "source": [
    "## One-File Solution!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "38da137d-51c7-43f6-a46d-1f219df24db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(final_file, mode='a', if_sheet_exists='overlay') as writer:\n",
    "    wb = writer.book\n",
    "\n",
    "    for ticker in stocks_list:\n",
    "        data_to_append = pd.DataFrame(new_df.drop(columns='Date').loc[ticker]).transpose()\n",
    "        data_to_append.to_excel(excel_writer=writer, engine='openpyxl', sheet_name=ticker.lower(), index=False, header=False, startrow=correct_row, startcol=1)\n",
    "    wb.save(final_file)\n",
    "    wb.close()\n",
    "\n",
    "# wb.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbb9c32-28c2-4c0b-ba98-13c1b51a5a4a",
   "metadata": {},
   "source": [
    "* Tentativa 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c93d84-0d51-4f2b-96c8-780983523e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker in stocks_list:\n",
    "    data_to_append = pd.DataFrame(new_df.drop(columns='Date').loc[ticker]).transpose()\n",
    "    data_to_append.to_excel(excel_writer=writer, engine='xlsxwriter', sheet_name=ticker, index=False, header=False, startrow=correct_row, startcol=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a80468c-7374-4504-aa8f-1dcebbc5040f",
   "metadata": {},
   "source": [
    "# Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef7cdaa-e3ff-4eb0-8c0e-630e6f3216e5",
   "metadata": {},
   "source": [
    ">Note that creating an ExcelWriter object with a file name that already exists will result in the contents of the existing file being erased."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa66c12-e874-4d35-9674-39a970d8d9a1",
   "metadata": {},
   "source": [
    "> Because of the above note, it might be a good idea to first ship each dataframe to an entirely new excel file, and THEN use pywin32 to copy the cells and paste them on the ACTUAL destination file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83692012-d7cb-42af-8eff-a07045d85b56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a04e8e8-ae58-4592-b162-6564bec29545",
   "metadata": {},
   "source": [
    "# Tests down below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d75f90b4-328a-4fdb-824c-682d856a5eb3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[93], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mExcelWriter(path, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenpyxl\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m writer:\n\u001b[0;32m      2\u001b[0m     aapl_df\u001b[38;5;241m.\u001b[39mto_excel(writer, sheet_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maapl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:75\u001b[0m, in \u001b[0;36mOpenpyxlWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenpyxl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_workbook\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_book \u001b[38;5;241m=\u001b[39m load_workbook(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles\u001b[38;5;241m.\u001b[39mhandle, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mengine_kwargs)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles\u001b[38;5;241m.\u001b[39mhandle\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openpyxl\\reader\\excel.py:348\u001b[0m, in \u001b[0;36mload_workbook\u001b[1;34m(filename, read_only, keep_vba, data_only, keep_links, rich_text)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Open the given filename and return the workbook\u001b[39;00m\n\u001b[0;32m    319\u001b[0m \n\u001b[0;32m    320\u001b[0m \u001b[38;5;124;03m:param filename: the path to open or a file-like object\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    344\u001b[0m \n\u001b[0;32m    345\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    346\u001b[0m reader \u001b[38;5;241m=\u001b[39m ExcelReader(filename, read_only, keep_vba,\n\u001b[0;32m    347\u001b[0m                      data_only, keep_links, rich_text)\n\u001b[1;32m--> 348\u001b[0m reader\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m reader\u001b[38;5;241m.\u001b[39mwb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openpyxl\\reader\\excel.py:303\u001b[0m, in \u001b[0;36mExcelReader.read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    301\u001b[0m apply_stylesheet(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marchive, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwb)\n\u001b[0;32m    302\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread worksheets\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 303\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_worksheets()\n\u001b[0;32m    304\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massign names\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparser\u001b[38;5;241m.\u001b[39massign_names()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openpyxl\\reader\\excel.py:237\u001b[0m, in \u001b[0;36mExcelReader.read_worksheets\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    235\u001b[0m     ws\u001b[38;5;241m.\u001b[39m_rels \u001b[38;5;241m=\u001b[39m rels\n\u001b[0;32m    236\u001b[0m     ws_parser \u001b[38;5;241m=\u001b[39m WorksheetReader(ws, fh, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshared_strings, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_only, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrich_text)\n\u001b[1;32m--> 237\u001b[0m     ws_parser\u001b[38;5;241m.\u001b[39mbind_all()\n\u001b[0;32m    238\u001b[0m     fh\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    240\u001b[0m \u001b[38;5;66;03m# assign any comments to cells\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:465\u001b[0m, in \u001b[0;36mopenpyxl.worksheet._reader.WorksheetReader.bind_all\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:368\u001b[0m, in \u001b[0;36mopenpyxl.worksheet._reader.WorksheetReader.bind_cells\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:156\u001b[0m, in \u001b[0;36mparse\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\xml\\etree\\ElementTree.py:1238\u001b[0m, in \u001b[0;36miterparse.<locals>.iterator\u001b[1;34m(source)\u001b[0m\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m pullparser\u001b[38;5;241m.\u001b[39mread_events()\n\u001b[0;32m   1237\u001b[0m \u001b[38;5;66;03m# load event buffer\u001b[39;00m\n\u001b[1;32m-> 1238\u001b[0m data \u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m16\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024\u001b[39m)\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[0;32m   1240\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\zipfile\\__init__.py:989\u001b[0m, in \u001b[0;36mZipExtFile.read\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    987\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof:\n\u001b[1;32m--> 989\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read1(n)\n\u001b[0;32m    990\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(data):\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_readbuffer \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\zipfile\\__init__.py:1057\u001b[0m, in \u001b[0;36mZipExtFile._read1\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1055\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39munconsumed_tail\n\u001b[0;32m   1056\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlen\u001b[39m(data):\n\u001b[1;32m-> 1057\u001b[0m         data \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read2(n \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(data))\n\u001b[0;32m   1058\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1059\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read2(n)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\zipfile\\__init__.py:1089\u001b[0m, in \u001b[0;36mZipExtFile._read2\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1086\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(n, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMIN_READ_SIZE)\n\u001b[0;32m   1087\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(n, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_left)\n\u001b[1;32m-> 1089\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fileobj\u001b[38;5;241m.\u001b[39mread(n)\n\u001b[0;32m   1090\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_left \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data)\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\zipfile\\__init__.py:808\u001b[0m, in \u001b[0;36m_SharedFile.read\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt read from the ZIP file while there \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    805\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis an open writing handle on it. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    806\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClose the writing handle before trying to read.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    807\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pos)\n\u001b[1;32m--> 808\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file\u001b[38;5;241m.\u001b[39mread(n)\n\u001b[0;32m    809\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file\u001b[38;5;241m.\u001b[39mtell()\n\u001b[0;32m    810\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with pd.ExcelWriter(path, mode=\"a\", engine=\"openpyxl\") as writer:\n",
    "    aapl_df.to_excel(writer, sheet_name='aapl')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "b95377a5-9ec4-46ff-b109-d8b79acddff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Close    196.98\n",
      "High     198.83\n",
      "Low      194.42\n",
      "Open     197.20\n",
      "Name: AAPL, dtype: float64\n",
      "\n",
      "\n",
      "Close    241.37\n",
      "High     244.34\n",
      "Low      237.68\n",
      "Open     243.47\n",
      "Name: TSLA, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for stock in stocks_list:\n",
    "    print(df.loc[stock])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adf135b-f874-4d67-a60d-b5dcba9d920a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
